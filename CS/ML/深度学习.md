传统上，参数越多模型复杂度越高，容量越大，越容易完成复杂的学习任务；  
但是也容易：训练效率低、易陷入过拟合的问题；  
随着云计算、大数据的到来，计算能力大幅提高解决效率问题，训练数据大幅增加解决了过拟合问题；因此“深度学习”开始流行。

增加隐层的层数比增加隐层内神经元的数目更有效果；  
此时不能用BP的算法，因为误差在隐层内逆传播会“发散”。  

#### 方法
1. 无监督逐层训练，每次训练一个隐层的节点，把上一层的输出作为本层的输入，本层的输出作为下一层的输入；再这样的预训练结束后，再对**整个网络**微调。
2. 权共享：让一组神经元使用相同的连接权（w相同？），这是在卷积神经网络CNN中发挥了重要作用。