## Introduction
优点：计算复杂度不高，易于理解；可以处理不相关特征数据；对中间值的缺失不敏感；

决策树的关键在于是分支节点所包含的样本尽可能属于同一类别，即**纯度purity**越来越高。
所以ID3算法的关键就是定义了这样一种度量。

每次划分前比较每个划分准则（属性）的信息增益最大的值；

信息：  
$$l(x_i)=log_2 p(x_i)$$

$p(X_i)是分类的概率；  
信息熵：  
$$Ent(D)=-\sum^n_{i=1}p(x_i)log_2 p(x_i)$$

信息增益：  
$$Gain(D,a)=Ent(D)-\sum\frac{|D^v|}{|D|}H(D^v)$$
