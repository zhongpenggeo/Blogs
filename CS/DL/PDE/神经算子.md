关键词：

- 参数到解的映射，即整个PDE家族的解

- 不依赖于离散化；mesh-invariant

## 1. 傅里叶神经算子

### 1.1 之前的方法

#### 1. 有限维算子

将解算子参数化为有限维欧几里得空间之间的深度卷积网络，依赖于mesh。即传统的监督算法

#### 2. Neural-FEM

将解函数直接参数化为神经网络。该方法旨在为 PDE 的特定实例建模，而不是解算子。它具备 mesh 独立性并且准确，但是对于函数参数 / 系数的任何给定新实例，它都需要训练新的神经网络。

即PINNs

### 1.2. 研究

能够学习无限维函数空间之间映射的新型深度学习架构——傅里叶神经算子，通过傅里叶空间中的线性变换实例化积分算子

- 傅里叶神经算子方法共享相同的学得网络参数，而与出于计算目的在输入和输出空间上使用的离散化无关。
- 对于 parametric PDE，傅里叶神经算子始终优于所有现有的深度学习方法。其误差率在伯格斯方程上降低了 30%，在达西流动问题上降低了 60%，在纳维 - 斯托克斯方程（雷诺数为 10000 的湍流状态）上降低了 30%（如图 1b 所示）。在学习整个时间序列的映射时，该方法在雷诺数为 1000 时，达到了 < 1% 的误差，在雷诺数为 10000 时，误差为 8%。

### 1.3 从函数到算子

算子：

- 函数到函数的映射；。比如微分算子把三次函数x³变成二次函数3x²
- 无限维到无限维

最早**深度算子网络”**（DeepONet），就是用算子的方法求解PDE



个人总结：

参数还只是不变的参数，对于空间随机变化的参数似乎还没有怎么应用



参考：[无惧分辨率变化，顽强求解PDE家族：加州理工学院等提出傅里叶神经算子方法 | 机器之心 (jiqizhixin.com)](https://www.jiqizhixin.com/articles/2020-10-23-7)