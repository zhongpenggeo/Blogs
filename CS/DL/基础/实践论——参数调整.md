1. 从一个好的基准开始，比如某一篇高质量论文
2. 每次只调整一个参数，观察其改变
3. 重复步骤2很多次，得到insights about
   1. 那个超参数最重要
   2. 超参数的敏感度（对高敏感度参数需要仔细调整）
      1. Adam就是低敏感参数（相较于SGD），所以尽管Adam未必比SGD好，但更容易调整。
   3. 寻找最佳范围



最好保存调参日志。TensorBord；weights & bias；

### Automated Machine Learning（AutoML）

所有的子任务尽可能自动化，如数据标注、数据清理、模型选择；

#### Hyperparameters optimization （HPO）

用搜索算法寻找最佳的超参数集合

#### Neural architecture search（NAS）

构造最佳网络模型

 



#### 参考

[9.1 模型调参【斯坦福21秋季：实用机器学习中文版】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1vQ4y1e7LF/?vd_source=51835ba198b79c5277a5fcadc11bd9ff)

[9.2 超参数优化【斯坦福21秋季：实用机器学习中文版】_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1FM4y1c7yG/?vd_source=51835ba198b79c5277a5fcadc11bd9ff)