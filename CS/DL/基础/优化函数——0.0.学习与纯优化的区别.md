机器学习通常是间接作用，我们关注某型性能度量 $P$，其定义于**测试集上**且可能不可解。因此我们智能间接的优化 $P$ ，即通过降低代价函数 $J(\boldsymbol{\theta})$ 来提高 $P$。

而纯优化是最小化目标函数 $J$ 本身。

通常，代价函数可写为训练集上的平均，如
$$
J(\boldsymbol{\theta}) = \mathbb{E}_{(\boldsymbol{x},y)\sim \hat{p}_{data}} L(f(\boldsymbol{x;\theta}),y)
$$
其中，$L$ 是每个样本的损失函数，$f(\boldsymbol{x;\theta})$ 是输入 $\boldsymbol{x}$ 是的预测输出，$\hat{p}_{data}$ 是经验分布。

监督学习中，$y$ 是目标输出。

通常，我们希望最小化曲子数据生成分布 ${p}_{data}$ 的期望，而不仅仅是有限训练集上的目标函数：
$$
J^*(\boldsymbol{\theta}) = \mathbb{E}_{(\boldsymbol{x},y)\sim {p}_{data}} L(f(\boldsymbol{x;\theta}),y)
$$

### 经验风险最小化
机器学习算法的目标是降低上式 所示的期望泛化误差。这个数据量被称为 `风险`（risk）。在这里，我们强调该期望取自真实的潜在分布 $p_{data}$。如果我们知道了真实分布 $p_{data}(x,y)$，那么最小化风险变成了一个可以被优化算法解决的优化问题。然们遇到的机器学习问题，通常是不知道真是分布，只知道训练集中的样本。

用训练集上的经验分布 $\hat{p}(\boldsymbol{x},y)$  代替真实分布$p(\boldsymbol{x},y)$，来最小化`经验风险`
$$
\mathbb{E}_{(x,y)\sim \hat{p}_{data}} L(f(\boldsymbol{x;\theta}),y)=\frac{1}{m}\sum^m_{i=1}LL(f(\boldsymbol{x})^{(i)};\boldsymbol{\theta}),y)
$$
$m$ 表示训练样本数量。

基于最小化这种平均训练误差的训练过程被称为 `经验风险最小化`。

然而， 经验风险最小化很容易导致过拟合。高容量的模型会简单地记住训练集。在很多情况下， 经验风险最小化并非真的可行。最有效的现代优化算法是基于梯度下降的，但是很多有用的损失函数，如 0 - 1 损失，没有有效的导数（导数要么为零，要么处处未定义）。这两个问题说明，在深度学习中我们很少使用经验风险最小化。反之，我们会使用一个稍有不同的方法，我们真正优化的目标会更加不同于我们希望优化的目标。  

### 代理损失函数和提前终止

有时，我们真正关心的损失函数（比如分类误差）并不能被高效地优化。例如，即使对于线性分类器而言，精确地最小化 0 - 1 损失通常是不可解的（复杂度是输入维数的指数级别） (Marcotte and Savard, 1992)。在这种情况下，我们通常会优化 `代理损失函数`（surrogate loss function）。 代理损失函数作为原目标的代理，还具备一些优点。例如，正确类别的负对数似然通常用作 0 - 1 损失的替代。负对数似然允许模型估计给定样本的类别的条件概率，如果该模型效果好，那么它能够输出期望最小分类误差所对应的类别。  

在某些情况下， 代理损失函数比原函数学到的更多。

一般的优化和我们用于训练算法的优化有一个重要不同：训练算法通常不会停止在局部极小点。反之， 机器学习通常优化代理损失函数，但是在基于提前终止（第 7.8 节）的收敛条件满足时停止。通常， 提前终止使用真实潜在损失函数，如验证集上的 0 - 1 损失，并设计为在过拟合发生之前终止。与纯优化不同的是， 提前终止时代理损失函数仍然有较大的导数，而纯优化终止时导数较小。 

 