### 贝叶斯定理

$$
P(B|A)=\frac{P(A|B)P(B)}{P(A)}
$$



已知：有N个苹果，和M个梨子，苹果为黄色的概率为20%，梨子为黄色的概率为80%，问，假如我在这堆水果中观察到了一个黄色的水果，问这个水果是梨子的概率是多少

用数学语言：已知$P(apple)=\frac{N}{N+M}$，$P(pear)=\frac{M}{N+M}$，$P(yellow|apple)=20\%$，$P(yellow|pear)=80\%$，求$P(pear|yellow)$。

我们需要 1. 要求出全部水果中为黄色的水果数目。 2. 求出黄色的梨子数目

对于1：P(yellow) * (N + M), P(yellow) = p(apple) * P(yellow|apple) + P(pear) * p(yellow|pear)；

对于2：P(yellow|pear) * M

用2中黄色梨子数量除以1中黄色水果的数量即为问题的答案

P(pear|yellow) = P(yellow|pear) * p(pear) / [P(apple) * P(yellow|apple) + P(pear) * P(yellow|pear)]

即：P(pear|yellow) = P(yellow,pear) / P(yellow)

也就推出了贝叶斯定理：
$$
P(pear|yellow)=\frac{P(yellow|pear)P(pear)}{P(yellow)}
$$


### 机器学习中的应用

我们对模型参数 $\mathbf{w}$ 进⾏推断时，在观察到数据之前，我们首先可以有⼀些关于参数$\mathbf{w}$的假设，这以**先验概率**$p(\mathbf{w})$ 的形式给出；根据 $\mathbf{w}$ 表达预测目标数据 $D$ 可以通过条件概率$p(D|\mathbf{w})$ 表达，贝叶斯定理为
$$
p(\mathbf{w}|D)=\frac{p(D|\mathbf{w})p(\mathbf{w})}{p(D)}
$$
它让我们能够通过后验概率 $p(\mathbf{w}|D)$ ，**在观测到 $D$ 之后估计 $\mathbf{w}$ 的不确定性**。贝叶斯定理右侧量 $p(D|\mathbf{w})$由观测数据集 $D$ 来估计，可以被看成参数 $\mathbf{w}$ 的函数，称为似然函数 (likelihood function)。它表达了在不同的参数向量 $\mathbf{w}$ 下，观测数据出现的可能性的⼤⼩。贝叶斯公式右侧分母是⼀个归⼀化常数，确保了左侧的后验概率分布是⼀个合理的概率密度，积分为 1，对公式两侧关于 $\mathbf{w}$ 进⾏积分， 我们可⽤后验概率分布和似然函数来表达贝叶斯定理的分母
$$
p(D)=\int p(D|\mathbf{w})p(w)d\mathbf{w}
$$


在似然函数$p(D|\mathbf{w})$中， $\mathbf{w}$ 被认为是一个固定的参数，它的值由某种形式的估计来确定，这个估计的误差通过考察可能的数据集$D$ 的概率分布来得到，这也是我们使用大部分机器学习或深度学习模型常见的做法。而贝叶斯定理的观点则认为  $\mathbf{w}$ 是不确定的， 我们通过观察到的数据 $D$ 估计 $\mathbf{w}$ 的概率分布来表达参数的不确定性。

贝叶斯观点的⼀个优点是天然包含先验概率。例如，假定投掷⼀枚普通的硬币 3 次，每次都是正⾯朝上，经典的最⼤似然模型在估计硬币正⾯朝上的概率时结果会是 1，表示所有未来的投掷都会是正⾯朝上。相反，⼀个带有合理的先验的贝叶斯的⽅法将不会得出这么极端的结论。在第一篇文章就讲过，如果使用带贝叶斯估计的模型相当于增加了 L2 正则化（相当于加入了一种关于 $\mathbf{w}$ 的先验概率？，可以有效防止过拟合，尤其在有限数据集上这种效果更为明显。

然而先验概率$p(\mathbf{w})$的选择是十分麻烦的，一种针对贝叶斯⽅法的⼴泛批评就是先验概率的选择通常是为了计算的⽅便⽽不是为了反映出任何先验的知识。实际上当先验选择不好的时候，贝叶斯⽅法有很⼤的可能性会给出错误的结果



参考：

[概率分布 Probability Distribution: 贝叶斯概率，Beta 分布，狄利克雷分布 - PRML - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/371271147)

[贝叶斯、概率分布与机器学习 - LeftNotEasy - 博客园 (cnblogs.com)](https://www.cnblogs.com/leftnoteasy/archive/2010/09/27/1837163.html)