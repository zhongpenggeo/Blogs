表达对模型参数适当值得先验知识。

经常想要表达的一种常见依赖是**某些参数应当彼此接近**。考虑以下情形：两个模型执行相同的分类任务（具有相同类别），但输入的分布稍有不同。我们由参数为 $\boldsymbol{w}^{(A)}$ 的模型A和参数为　$\boldsymbol{w}^{(B)}$ 的模型B，得到不同但是相关的输出：
$$
\hat{y}^{(A)} = f(\boldsymbol{w}^{(A)},\boldsymbol{x})\\
\hat{y}^{(B)} = f(\boldsymbol{w}^{(B)},\boldsymbol{x})
$$
我们认为模型参数应该彼此靠近,可以通过正则化利用此信息，比如使用参数范数惩罚：$\Omega(\boldsymbol{w}^{(A)},\boldsymbol{w}^{(B)})=||\boldsymbol{w}^{(A)}-\boldsymbol{w}^{(B)}||^2$。这里使用的L2惩罚。


这种方法由Lasserre et al. (2006) 提出， 正则化一个模型（监督模式下训练的分类器）的参数，使其接近另一个无监督模式下训练的模型（捕捉观察到的输入数据的分布）的参数。这种构造架构使得许多分类模型中的参数能与之对应的无监督模型的参数匹配。  



另一种更流行的方法是使用约束 强迫某些参数相等，即`参数共享`，与正则化参数使其接近相比，参数共享需要的存储量更少（CNN即采用这一模式）。

