### 数据集增强
让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练，增加数据的一种方法是创建假数据并添加到训练集中。

对于分类任务来说这种方法最简单。分类器需要一个复杂的高维输入 $\boldsymbol{x}$，并用单个类别标识 $y$ 来概括 $\boldsymbol{x}$。这要求对各种各样的变换保持不变。因此可以通过转换训练集中的 $\boldsymbol{x}$ 来生成新的 $（\boldsymbol{x},y)$ 对。

但在密度估计任务中生成新的假数据是很困难的。

数据集增加对语音识别任务也是有效的( Jaitly and Hinton, 2013)

### 注入噪声

对于分类甚至一些回归任务而言，即使小的随机噪声被加到输入，任务应该还是可以被解决的。然而，神经网络被证明对噪声不是非常健壮(Tang and Eliasmith, 2010)。改善健壮性的方法之一是简单地将随机噪声添加到输入再进行训练。

向隐藏单元施加噪声也是可行地，这可以被看作**在多个抽象层上进行的数据集增强**。Poole et al. (2014) 最近表明，噪声的幅度被细心调整后该方法是非常高效的。另一个正则化策略 **Dropout 可以被看作是通过与噪声相乘构建新输入的过程**。 

通常，普适操作（例如，向输入添加高斯噪声）被认为是机器学习算法的一部分，而特定于一个应用领域（如随机地裁剪图像）的操作被认为是独立的预处理步骤。  

参考：

《Deep Learning》花书 7.4 节