使用什么误差度量，是必要的第一步。

值得注意的是对于大多数应用而言，不可能实现绝对零误差。即使你有无限的训练数据，并且恢复了真正的概率分布， **贝叶斯误差仍定义了能达到的最小错误率**。这是因为输入特征可能无法包含输出变量的完整信息，或是因为系统可能本质上是随机的。当然我们还会受限于有限的训练数据。  

还有一种比较重要的是度量的选择。

### 极端二份器

有时，我们需要训练检测某些罕见事件的二元分类器 ，选择度量`精度`(precision)和`召回率` (recall)。

- 精度是模型报告的检测是正确的比率，
- 召回率是真实事件被检测到的比率。

当使用精度和召回率时，通常会画`PR曲线`， $y$ 轴表示精度，$x$ 轴表示召回率。

多数时候，希望用一个数而不是曲线来概括分类器性能，考虑将精度 $p$ 和召回率 $r$ 转换为`F分数`：
$$
F=\frac{2pr}{p+r}
$$
或者，使用PR曲线下方的总面积。

### 置信度判断

有时机器学习系统可能会拒绝左除判断。此时，一种自然的的性能度量是`覆盖`(coverage)。覆盖是机器学习系统能够产生响应的样本所占的比率。我们权衡覆盖和精度，保证覆盖率的条件下提高精度。

