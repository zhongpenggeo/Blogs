pytorch 1.8 开始支持复数



**注意：复数矩阵如果做了切片可能会变为float数据类型**



### 运算

`torchmv()`和`torch.matmul()`等已经支持复数计算，比模仿它们的浮点数计算要快；use vectorized assembly instructions and specialized kernels (e.g. LAPACK, cuBlas).来优化计算操作

### 类型

torch.cfloat and torch.cdouble

注意：complex的类型与浮点数类型相关，如果浮点数是float64，那么就是complex128；否则是complex64

### 函数支持

所有的factory functions除了[`torch.linspace()`](https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace), [`torch.logspace()`](https://pytorch.org/docs/stable/generated/torch.logspace.html#torch.logspace), and [`torch.arange()`](https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange)都支持复数

### 对旧版本的支持

把2向量shape(...,2) 变为复数，通过[`torch.view_as_complex()`](https://pytorch.org/docs/stable/generated/torch.view_as_complex.html#torch.view_as_complex) and [`torch.view_as_real()`](https://pytorch.org/docs/stable/generated/torch.view_as_real.html#torch.view_as_real)；注意这个不是copy操作，而是直接返回view

### 分为实虚部

```python
>>> y.real
tensor([ 0.6125, -0.3773, -0.0861])
>>> y.imag
tensor([-0.1681,  1.3487, -0.7981])

>>> y.real.mul_(2)
tensor([ 1.2250, -0.7546, -0.1722])
>>> y
tensor([ 1.2250-0.1681j, -0.7546+1.3487j, -0.1722-0.7981j])
>>> y.real.stride()
(2,)
```



### 幅角与绝对值

[`torch.angle()`](https://pytorch.org/docs/stable/generated/torch.angle.html#torch.angle) and torch.abs.

```python
x1=torch.tensor([3j, 4+4j])
>>> x1.abs()
tensor([3.0000, 5.6569])
>>> x1.angle()
tensor([1.5708, 0.7854])
```

### 线性代数

很多操作如[`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul), [`torch.svd()`](https://pytorch.org/docs/stable/generated/torch.svd.html#torch.svd), [`torch.solve()`](https://pytorch.org/docs/stable/generated/torch.solve.html#torch.solve) etc.支持复数

### serialization



### 自动求导

PyTorch supports autograd for complex tensors. The gradient computed is the Conjugate Wirtinger derivative, the negative of which is precisely the direction of steepest descent used in Gradient Descent algorithm. Thus, all the existing optimizers work out of the box with complex parameters. For more details, check out the note [Autograd for Complex Numbers](https://pytorch.org/docs/stable/notes/autograd.html#complex-autograd-doc).

We do not fully support the following subsystems:

- Quantization
- JIT
- Sparse Tensors
- Distributed





参考：https://pytorch.org/docs/stable/complex_numbers.html

