### 问题

每次运行程序产生的结果不太一样。有两种不太一样

1. 每次restart kernel后结果都不太一样
2. 每次restart kernel结果一样，但继续多次运行同一个模型结果还是不同（但每一回restart后再运行的N次结果是总是相同的），比如第一次restart后三次运行的结果分别是1e-4, 1e-5,1e-3，那再次restart后三次的结果还是这样



### 解决方案

#### 问题一

在主程序里固定随机种子（在import 子模块之前）

```python
def setup_seed(seed):
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.
    np.random.seed(seed)  # Numpy module.
#     random.seed(seed)  # Python random module.
    torch.manual_seed(seed)
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
```



#### 问题二

在调用的类或者子模块里再次固定随机种子（比如我就喜欢再basic_model class的initiation中再次设定随机数）



另外结果表明，只需要在关键模块里加入随机种子即可



函数参考：https://pytorch.org/docs/stable/torch.html#torch.get_rng_state