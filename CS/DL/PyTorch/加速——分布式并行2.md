DDP：distributeddataparallel

注意目前并行对复数支持还不够，建议分为实部虚部运行。

## 0. 概述

- 主节点：用于同步的gpu
- process group：所有使用的gpu组成的区组
- rank： 进程id
- world size： 总进程数

DDP还可以gather/scatter tensors/objects other than gradients by `torch.distributed.gather/scatter/reduce`.

#### 步骤

- 建立进程组
- 数据分割到不到进程
- wrap model到DDP
- 训练 模型
- 清楚进程（类似C语言中释放进程）
- *optional: gather extra data among processes (possibly needed for distributed testing), which is basically one line of code;*

### 1. 建立进程组

```python
import torch.distributed as dist
def setup(rank, world_size):
    os.environ['MASTER_ADDR'] = 'localhost'
    os.environ['MASTER_PORT'] = '12355'
    dist.init_process_group("nccl", rank=rank, world_size=world_size)
```

### 2. 分割数据

`DistributedSampler`把数据分割为*world_size* 份，并分发到不同进程而不需duplication

```python
from torch.utils.data.distributed import DistributedSampler
def prepare(rank, world_size, batch_size=32, pin_memory=False, num_workers=0):
    dataset = Your_Dataset()
    sampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)
    
    dataloader = DataLoader(dataset, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers, drop_last=False, shuffle=False, sampler=sampler)
    
    return dataloader
```

**说明**：

- 设置`drop_last=False`，那么会自动pad(=0?)，比如把10个数据[0,1,2,3,4,5,6,7,8,9]分到3个进程，则每个子集为：[0,3,6,9]，[0,4,7,0] ，[2,5,8,0]
- 否则，[0,3,6] at *rank*=1, [1,4,7] at *rank*=2, and [2,5,8] at *rank*=3

It is very simple to customize our Sampler. We only need to create a class, then define its `__iter__()` and `__len__()` function. Refer to the [official documentation](https://pytorch.org/docs/stable/data.html?highlight=distributedsampler#torch.utils.data.distributed.DistributedSampler) for more details.

**建议**：设置**num_workers=0**，**pin_memory=False**

### 3. 封装模型到DDP

1. 把模型移到指定gpu
2. 封装到DDP

注意，模型计算时会自动从cpu转移到gpu

```python
from torch.nn.parallel import DistributedDataParallel as DDP
def main(rank, world_size):
    # setup the process groups
    setup(rank, world_size)
    # prepare the dataloader
    dataloader = prepare(rank, world_size)
    
    # instantiate the model(it's your own model) and move it to the right device
    model = Model().to(rank)
    
    # wrap the model with DDP
    # device_ids tell DDP where is your model
    # output_device tells DDP where to output, in our case, it is rank
    # find_unused_parameters=True instructs DDP to find unused output of the forward() function of any module in the model
    model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)
```

#### 一些trick

- 如果要自定义DDP，要参考`model.module`类
- 保存时，`state_dict`会给所有参数添加*module prefix*
- 因此，如果要加载一个DDP到一个非DDP模型，要手动去除前缀

```python
# in case we load a DDP model checkpoint to a non-DDP model
model_dict = OrderedDict()
pattern = re.compile('module.')
for k,v in state_dict.items():
    if re.search("module", k):
        model_dict[re.sub(pattern, '', k)] = v
    else:
        model_dict = state_dict
model.load_state_dict(model_dict)
```

### 4. 训练模型

多任务的核心：子进程和父进程运行相同的代码

`torch.multiprocessing`用于创建多任务

`spawn`函数

先定义一个训练模型，再spawn

```python
def main(rank, world_size):
    # setup the process groups
    setup(rank, world_size)
    # prepare the dataloader
    dataloader = prepare(rank, world_size)
    
    # instantiate the model(it's your own model) and move it to the right device
    model = Your_Model().to(rank)
    
    # wrap the model with DDP
    # device_ids tell DDP where is your model
    # output_device tells DDP where to output, in our case, it is rank
    # find_unused_parameters=True instructs DDP to find unused output of the forward() function of any module in the model
    model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=True)
    #################### The above is defined previously
   
    optimizer = Your_Optimizer()
    loss_fn = Your_Loss()
    for epoch in epochs:
        # if we are using DistributedSampler, we have to tell it which epoch this is
        dataloader.sampler.set_epoch(epoch)       
        
        for step, x in enumerate(dataloader):
            optimizer.zero_grad(set_to_none=True)
            
            pred = model(x)
            label = x['label']
            
            loss = loss_fn(pred, label)
            loss.backward()
            optimizer.step()
    cleanup()
```

main程序运行每一个并行的进程，然后调用spawn

```python
import torch.multiprocessing as mp
if __name__ == '__main__':
    # suppose we have 3 gpus
    world_size = 3    
    mp.spawn(
        main,
        args=(world_size),
        nprocs=world_size
    )
```

spawn会自动分配rank，默认rank为0是主进程

### 5. 清除

```python
def cleanup():
    dist.destroy_process_group()
```

### 6. 收集信息

 **One should always assign** `torch.cuda.set_device(rank)` **before using** `all_gather_xxx. And, if we want to store a tensor in the object, it must locate at the `**output_device**`

```python
def main(rank, world_size):
    torch.cuda.set_device(rank)
    data = {
        'tensor': torch.ones(3,device=rank) + rank,
        'list': [1,2,3] + rank,
        'dict': {'rank':rank}   
    }
    
    # we have to create enough room to store the collected objects
    outputs = [None for _ in range(world_size)]
    # the first argument is the collected lists, the second argument is the data unique in each process
    dist.all_gather_object(outputs, data)
    # we only want to operate on the collected objects at master node
    if rank == 0:
        print(outputs)
```



## 其他

### IO操作

所有IO操作都应该与主进程隔离。

```python
if rank == 0:
    if not os.path.exists('/spell/checkpoints/'):
        os.mkdir('/spell/checkpoints/')
        torch.save(
            model.state_dict(),
            f'/spell/checkpoints/model_{epoch}.pth'
        )
```

此外，还需要考虑loss同步的问题

### 全局BN

```python
model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)
model = DDP(model, device_ids=[local_rank], output_device=local_rank)
```



参考：[A Comprehensive Tutorial to Pytorch DistributedDataParallel | by namespace-Pt | CodeX | Medium](https://medium.com/codex/a-comprehensive-tutorial-to-pytorch-distributeddataparallel-1f4b42bb1b51)

[Distributed model training in PyTorch using DistributedDataParallel (spell.ml)](https://spell.ml/blog/pytorch-distributed-data-parallel-XvEaABIAAB8Ars0e)

[Pytorch distributed data parallel step by step Dongda’s homepage (dongdongbh.tech)](https://dongdongbh.tech/ddp/)

[Multi-GPU Computing with Pytorch (Draft) (srijithr.gitlab.io)](https://srijithr.gitlab.io/post/pytorchdist/)