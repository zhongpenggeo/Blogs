### 马尔可夫链蒙特卡罗算法（MCMC）

**MCMC方法是用来在概率空间，通过随机采样估算兴趣参数的后验分布**

#### 为什么需要MCMC

要对随机变量采样，需要满足两个前提：

- 概率密度函数可积
- 累计分布函数（即概率密度函数的积分）有反函数

如果前提不成立，则需要MCMC。

第二，对于高位随机变量，如$\mathbb{R}^{50}$，若每一维取100个点，则总共需要取$50^{100}$。因此MCMC可以解决维数灾难。

### 蒙特卡洛采样的基础

当无法精确计算或积分时，通常可以使用蒙特卡洛采样来近似。这种想法把积分视作某种分布下的期望，然后通过估计对应的平均值来近似这个期望。令
$$
s=\sum_x p(\boldsymbol{x})f(\boldsymbol{x}) = E_p[f(\boldsymbol{x})]
$$
或者
$$
s=\int p(\boldsymbol{x})f(\boldsymbol{x}) = E_p[f(\boldsymbol{x})]
$$
将我们所需要估计的和或者积分，写成期望的形式。$p$ 是一个关于随机变量 $\boldsymbol{x}$ 的概率分布（求和时）或者概率密度函数（求积分时）。简而言之，**用采样得到的期望近似求和或积分**。

我们可以通过从 $p$ 中抽取 $n$ 个样本 $\boldsymbol{x}^{(1)},\dots ,\boldsymbol{x}^{(n)}$ 开近似 $s$ 并得到一个经验平均值:
$$
\hat{s}_n = \frac{1}{n}\sum_{i=1}^n f(\boldsymbol{x}^{(i)})
$$
首先，$\hat{s}$ 是无偏的，由于
$$
\mathbb{E}[\hat{s}_n] =  \frac{1}{n}\sum_{i=1}^n \mathbb{E}[f(\boldsymbol{x}^{(i)})] = \frac{1}{n}\sum^n_{i=1} s=s
$$
根据大数定理和中心极限定理可以证明。pass

以上结论都依赖于我们可以从基准分布 $p(\boldsymbol{x})$ 中采样，但是该假设不一定一直成立。当无法从 $p$ 中采样时，一个备选是 **重要采样** ；另一个是构建一个收敛到目标分布的估计序列，即**马尔可夫蒙特卡洛方法**。

### 重要采样

在蒙特卡洛方法中，对积分分解，确定积分中哪一部分作为概率分布 $p(\boldsymbol{x})$ 那一部分作为被积函数 $f(\boldsymbol{x})$ 是很关键的一步。不存在唯一的分解，因为它总是可以写成
$$
p(\boldsymbol{x})f(\boldsymbol{x} = q(\boldsymbol{x})\frac{p(\boldsymbol{x})f(\boldsymbol{x})}{q(\boldsymbol{x})}
$$
这里，我们从 $q$ 分布中采样，

pass（看不懂q的引入）

### 马尔可夫链

马尔科夫链定义本身比较简单，它假设某一时刻状态转移的概率只依赖于它的前一个状态，即$P(X^{t+1}|X^1,\dots,X^t)=P(X^{t+1}|X^t)$。

因为某一时刻状态转移只依赖于它的前一个状态，那么求出系统中任意两个状态之间的转换概率，最终可得到状态转移概率函数。

![img](imags/v2-ec1b67de2537cfebb4cd8d6bc4811840_1440w.jpeg)

其转移概率矩阵为
$$
P = \begin{pmatrix} 0.6 & 0.2 & 0.2 \\ 0.3 & 0.4 & 0.3 \\ 0 & 0.3 & 0.7 \\ \end{pmatrix}
$$
若假设初始的三个概率分别是 $[0.5,0.3,0.2]$ ，即 $t_0$ 时刻，50%概率是Cheerful，30%概率是So-so，20%概率是Sad，将此代入转移概率，我们一直计算到 $t_{100}$ 看看是什么情况：

![img](imags/v2-b960e86ce39b7adced8c30d06523c4f5_1440w.jpeg)

可以发现，从10轮左右开始，我们的状态概率分布就不变了.

我们现在换一个初始概率分布试一试$[0.2,0.3,0.5]$

![img](imags/v2-9ad07ec26a838e4cb7675c5d872afdc6_1440w.jpeg)

可以看出，尽管这次我们采用了不同初始概率分布，最终状态的概率分布趋于同一个稳定的概率分布，也就是说我们的马尔科夫链模型的**状态转移矩阵收敛到的稳定概率分布与我们的初始状态概率分布无关**。也就是说，如果我们得到了这个稳定概率分布对应的马尔科夫链模型的状态转移矩阵，则我们可以用任意的概率分布样本开始，带入马尔科夫链模型的状态转移矩阵，这样经过一些序列的转换，最终就可以得到符合对应稳定概率分布的样本。

马尔可夫链在几个时期内对随机变量建模是不合理的方法，但可以用来计算该变量的长期趋势，且与初始状态无关.

如果我们从一个具体的初始状态 $x_0$ 开始, 沿着马氏链按照概率转移矩阵做跳转，那么我们得到一个转移序列 $x_0,x_1,\dots,x_n,\dots$，由于马氏链的收敛行为， $x_n,\dots$都将是平稳分布 $\pi(x)$ 的样本。

### 马尔科夫链蒙特卡洛算法

#### 马尔可夫链的细致平稳条件

在解决从平稳分布 $\pi$, 找到对应的马尔科夫链状态转移矩阵 $P$ 之前，我们还需要先看看马尔科夫链的细致平稳条件。

过程pass

从细致平稳条件可以得到，只要我们找到了可以使概率分布 $\pi(x)$ 满足细致平稳分布的矩阵 $P$ 即可。这给了我们寻找从平稳分布 $\pi$ , 找到对应的马尔科夫链状态转移矩阵 $P$ 的新思路。不过很难找到满足细致平稳条件

#### MCMC采样

一般情况下，目标平稳分布 $\pi(x)$ 和某一个马尔科夫链状态转移矩阵 $Q$ 不满足细致平稳条件，即：
$$
\pi(i)Q(i,j)\neq \pi(j)Q(j,i)
$$
引入一个$\alpha(i,j)$ ，使上式可以取等号
$$
\pi(i)Q(i,j)\alpha(i,j) =  \pi(j)Q(j,i)\alpha(j,i)
$$
如何才能成立？按照对称性：
$$
\alpha(i,j) = \pi(j)Q(j,i);\quad \pi(i)Q(i,j)=\alpha(j,i)
$$
然后我们就可以得到了分布 $\pi(x)$ 对让马尔科夫链状态转移矩阵 $P(i,j)=Q(i,j)\alpha(i,j)$。

其中 $\alpha(i,j)$ 一般称为接受率，取值在[0,1]之间，可理解为一个概率值。这里是以一个常见的马尔科夫链状态转移矩阵 $P$ 通过一定的接受-拒绝概率得到目标转移矩阵 $Q$

![img](imags/v2-48086a0f62774d98f6b672b91d2dcda0_1440w.webp)



参考：

[马尔可夫链蒙特卡罗算法（MCMC） - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/37121528)
