### 1. 联合概率

联合概率是指在[多元](https://baike.baidu.com/item/多元/7720306)的概率分布中多个[随机变量](https://baike.baidu.com/item/随机变量/828980)分别满足各自条件的[概率](https://baike.baidu.com/item/概率/828845)。假设X和Y都服从正态分布，那么P{X<4,Y<0}就是一个联合概率，表示X<4,Y<0两个条件同时成立的概率。表示两个事件共同发生的概率。A与B的联合概率表示为 P(AB) 或者P(A,B),或者P(A∩B)

### 2. 边缘概率

仅与单个随机变量有关的概率。假设有离散型随机变量x和y，其已知P(x,y)，可用下面的求和法则来计算P(x)
$$
\forall x\in x,P(x=x)=\sum_y P(x=x,y=y)
$$
对于连续型变量，则使用积分代替求和

### 3. 条件概率

给定x=x时, y=y的条件概率为P(y=y|x=x)，可以通过下面的公式计算：
$$
P(y=y|x=x)=\frac{P(y=y,x=x)}{P(x=x)}
$$

### 4. 条件概率的链式法则

多维联合概率分布，可以分解为只有一个变量的条件概率相乘的形式
$$
P(x^{1},x^{2},\cdots,x^{n})=P(x^{(1)})\prod_{i=2}^nP(x^{(i)}|x^{1},\cdots,x^{i-1})
$$

$$
P(a,b,c)=P(a|b,c)P(b,c)\\
P(a,b,c)=P(a|b,c)P(b|c)P(c)\\
p(b,c)=p(b|c)P(c)
$$

#### 正态分布

采用正态分布在很多应用中都是一个明智的选择。当我们由于缺乏关于某个实 数上分布的先验知识而不知道该选择怎样的形式时，正态分布是默认的比较好的选 择，其中有两个原因。

第一，我们想要建模的很多分布的真实情况是比较接近正态分布的。 中心极限 定理（central limit theorem）说明很多独立随机变量的和近似服从正态分布。这意 味着在实际中，很多复杂系统都可以被成功地建模成正态分布的噪声，即使系统可 以被分解成一些更结构化的部分。

第二，在具有相同方差的所有可能的概率分布中，正态分布在实数上具有最大 的不确定性。因此，我们可以认为正态分布是对模型加入的先验知识量最少的分布。

#### Dirac 分布和经验分布

我们希望概率分布中的所有质量都集中在一个点上。这可以通 过 **Dirac delta 函数**（Dirac delta function）δ(x) 定义概率密度函数来实现：

Dirac delta 函数被定义成在除了 0 以外的所有点的值都为 0，但是积分为 1（类似于脉冲函数）。

Dirac 分布经常作为 经验分布（empirical distribution）的一个组成部分出现：

经验分布将概率密度 这些点是给定的 数据集或者采样的集合。只有在定义连续型随机变量的经验分布时，Dirac delta 函 数才是必要的。对于离散型随机变量， 情况更加简单：经验分布可以被定义成一 个 Multinoulli 分布，对于每一个可能的输入，其概率可以简单地设为在训练集上那 个输入值的 **经验频率**（empirical frequency）。



最大似然估计：

给定一个概率分布D，我们已知其概率密度函数$f_D$和一个分布参数$\theta$，

然后我们从中抽出一个n个值的采样$X1,X2...Xn$，利用$f_D$估计他的似然函数L；

当我们获得$X1,...Xn$时，就可能得到一个$\theta$使L取到最大值，这时的$\theta$为最大似然估计。

因此，最大似然估计时样本的函数。

举例：

如果一个盒子里有三个硬币（重量不同），抛出正面的概率分别时：1/3、1/2、2/3.

然后你取出其中一个，抛80次，得到49次正面，31次方面，估计这是哪一个硬币？

![](./imags/345e94cfdbd3816d8f4ef2097fd5074c23e037be.svg+xml)

可以看到，p=2/3那个让似然函数取得最大值,这就是p的最大似然估计

参考：[https://medium.com/@2681506/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E7%8E%87%E8%AE%BA-cac83ecff91c](https://medium.com/@2681506/深度学习概率论-cac83ecff91c)
