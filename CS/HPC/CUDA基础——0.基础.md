### 对比单CPU

显示芯片通常具有更大的内存带宽。例如，NVIDIA 的 GeForce 8800GTX 具有超过50GB/s 的内存带宽，而目前高阶 CPU 的内存带宽则在 10GB/s 左右。

显示芯片具有更大量的执行单元。例如 GeForce 8800GTX 具有 128 个 “stream processors”，频率为 1.35GHz。CPU 频率通常较高，但是执行单元的数目则要少得多。

和高阶 CPU 相比，显卡的价格较为低廉。例如一张 GeForce 8800GT 包括512MB 内存的价格，和一颗 2.4GHz 四核心 CPU 的价格相若。

当然，使用显示芯片也有它的一些缺点：

显示芯片的运算单元数量很多，因此对于不能高度并行化的工作，所能带来的帮助就不大。

显示芯片目前通常只支持 32 bits 浮点数，且多半不能完全支持 IEEE 754 规格， 有些运算的精确度可能较低。目前许多显示芯片并没有分开的整数运算单元，因此整数运算的效率较差。

显示芯片通常不具有分支预测等复杂的流程控制单元，因此对于具有高度分支的程序，效率会比较差。

目前 GPGPU 的程序模型仍不成熟，也还没有公认的标准。例如 NVIDIA 和AMD/ATI 就有各自不同的程序模型。

### 架构

![这里写图片描述](imags/20160328222438203)

![这里写图片描述](imags/20160328223627977)

一个 block 中的 thread 能存取同一块共享的内存，而且可以快速进行同步的动作。

执行相同程序的 block，可以组成grid。不同 block 中的 thread 无法存取同一个共享的内存

因此，不同 block 中的 thread 能合作的程度是比较低的。不过，利用这个模式，可以让程序不用担心显示芯片实际上能同时执行的 thread 数目限制。例如，一个具有很少量执行单元的显示芯片，可能会把各个 block 中的 thread 顺序执行，而非同时执行。不同的 grid 则可以执行不同的程序（即 kernel）。

#### 执行模式

由于显示芯片大量并行计算的特性，它处理一些问题的方式，和一般 CPU 是不同的。主要的特点包括：

内存存取 latency 的问题：CPU 通常使用 cache 来减少存取主内存的次数，以避免内存 latency 影响到执行效率。显示芯片则多半没有 cache（或很小），而利用并行化执行的方式来隐藏内存的 latency（即，当第一个 thread 需要等待内存读取结果时，则开始执行第二个 thread，依此类推）。

分支指令的问题：CPU 通常利用分支预测等方式来减少分支指令造成的 pipeline bubble。显示芯片则多半使用类似处理内存 latency 的方式。不过，通常显示芯片处理分支的效率会比较差。

